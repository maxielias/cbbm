{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler, MaxAbsScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "plt.figure(figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kpis = pd.read_csv(\"data/kpis.csv\")\n",
    "\n",
    "oscwd = os.getcwd()\n",
    "\n",
    "# Load dataframe with BALANCE SHEET data (assets, liabilities and equity)\n",
    "df_gh = pd.read_csv(os.path.join(oscwd, \"data/GH.txt\"),\n",
    "                            dtype = {\n",
    "                                    'CODIGO': str, 'ENTIDAD': str, \n",
    "                                    'Grupo': int\n",
    "                                    }\n",
    "                                    # parse_dates=['Periodo'],\n",
    "                            )\n",
    "gh_8 = df_gh[\"CODIGO\"][df_gh[\"Grupo\"]==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE GH 8\n",
    "data_kpis = data_kpis[~data_kpis[\"ent\"].isin(gh_8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2015\n",
    "end = 2015\n",
    "data = data_kpis[(data_kpis[\"per\"]>=start)&(data_kpis[\"per\"]<=end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=\"per\")\n",
    "data = data.replace(0, np.nan).groupby([\"ent\", \"ind\"]).mean(\"val\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ent -> MAX VALUE:65203, MIN VALUE:7'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'adv_curr_acc_disc_doc_loans -> MAX VALUE:1.0, MIN VALUE:-0.30886401093589716'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'asset_tot_asset -> MAX VALUE:1.0, MIN VALUE:-0.007749632229632772'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dep_cap_assets -> MAX VALUE:0.2738649217197347, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'deriv_assets -> MAX VALUE:0.6136200171052026, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'exp_dep_cap_loans -> MAX VALUE:0.08871908448056487, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_lending_rate -> MAX VALUE:1.0, MIN VALUE:-0.17356318081339261'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_liable_rate -> MAX VALUE:0.644532923154354, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_spread -> MAX VALUE:1.0, MIN VALUE:-0.5742402169740609'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'liquidity_ratio -> MAX VALUE:1.0, MIN VALUE:-0.1298272213927181'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loan_avg_segment_asset -> MAX VALUE:1.0, MIN VALUE:-0.041647863935058954'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loans_cap_assets -> MAX VALUE:0.8302024606494827, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loans_cap_to_banks_assets -> MAX VALUE:1.0, MIN VALUE:-0.011038339790895843'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'net_int_inc_tot_income -> MAX VALUE:1.0, MIN VALUE:-0.1817985805605479'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'net_worth_assets -> MAX VALUE:1.0, MIN VALUE:-0.32534668149973794'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pers_cred_card_loans -> MAX VALUE:1.0, MIN VALUE:-0.4876516505064675'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'roe -> MAX VALUE:0.781047840719273, MIN VALUE:-1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'serv_rev_tot_inc -> MAX VALUE:1.0, MIN VALUE:-0.08010693679324783'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'titles_assets -> MAX VALUE:1.0, MIN VALUE:-0.2965741278054744'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ent -> MAX VALUE:65203, MIN VALUE:7'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'adv_curr_acc_disc_doc_loans -> MAX VALUE:1.6171621395269742, MIN VALUE:-0.4994831847479782'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'asset_tot_asset -> MAX VALUE:28.332310778979195, MIN VALUE:-0.21956498875274919'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dep_cap_assets -> MAX VALUE:0.35843732231800013, MIN VALUE:-1.3088106357951688'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'deriv_assets -> MAX VALUE:805.9357945861206, MIN VALUE:-1313.4118381407793'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'exp_dep_cap_loans -> MAX VALUE:1.4117612390203458, MIN VALUE:-15.912711986219959'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_lending_rate -> MAX VALUE:19.369009447821274, MIN VALUE:-3.3617468889685136'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_liable_rate -> MAX VALUE:1.310456280111184, MIN VALUE:-2.0331874959897953'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'implied_spread -> MAX VALUE:8.553542173839972, MIN VALUE:-4.911787913802646'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'liquidity_ratio -> MAX VALUE:9.247107008517176, MIN VALUE:-1.2005262088369146'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loan_avg_segment_asset -> MAX VALUE:7.58941548124992, MIN VALUE:-0.31608294330972664'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loans_cap_assets -> MAX VALUE:2.075230589041685, MIN VALUE:-2.4996680778543996'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loans_cap_to_banks_assets -> MAX VALUE:17.024887367266405, MIN VALUE:-0.18792649166161673'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'net_int_inc_tot_income -> MAX VALUE:323.2386235058754, MIN VALUE:-58.7643229357135'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'net_worth_assets -> MAX VALUE:2.912757827066778, MIN VALUE:-0.9476560930485639'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pers_cred_card_loans -> MAX VALUE:1.1133811578547477, MIN VALUE:-0.5429421592706696'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'roe -> MAX VALUE:2.4694939553886464, MIN VALUE:-3.161770414875573'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'serv_rev_tot_inc -> MAX VALUE:256.3900508588875, MIN VALUE:-20.538621598570497'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'titles_assets -> MAX VALUE:2.8670511993618306, MIN VALUE:-0.8502932088243741'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_pivot = data.pivot(index=\"ent\", columns=\"ind\", values=\"val\").fillna(0).reset_index()\n",
    "data_pivot_describe = data_pivot.describe()\n",
    "\n",
    "def scale_data(df, scaler):\n",
    "    df[df.columns[1:]] = scaler.fit_transform(df[df.columns[1:]])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_corr_matrix(df, method):\n",
    "    corr_matrix = df[df.columns[1:]].corr(method)\n",
    "\n",
    "    return corr_matrix\n",
    "\n",
    "scaler = {\n",
    "          \"maxabs_scaler\": MaxAbsScaler(),\n",
    "          \"robust_scaler\": RobustScaler()\n",
    "        }\n",
    "corr_method = ['pearson', 'kendall', 'spearman']\n",
    "\n",
    "sns.set(font_scale=0.8, rc={\"figure.figsize\":(20,20)})\n",
    "\n",
    "with pd.ExcelWriter('output/data_corr.xlsx') as writer:\n",
    "    for s, m in [(s, m) for s in scaler for m in corr_method]:\n",
    "        df_scaled = scale_data(data_pivot, scaler[s])\n",
    "        corr_matrix = get_corr_matrix(df_scaled, m)\n",
    "        corr_matrix.style.background_gradient(cmap=\"coolwarm\").to_excel(writer, sheet_name=f\"{s}_{m}\")\n",
    "        heatmap = sns.heatmap(corr_matrix, annot=True).set_title(f\"corr_matrix_{s}_{m}\")\n",
    "        fig = heatmap.get_figure()\n",
    "        fig.savefig(f\"graph/corr_matrix_{s}_{m}.png\", dpi=fig.dpi)\n",
    "        fig.clf()\n",
    "\n",
    "    for s in scaler:\n",
    "        df_scaled = scale_data(data_pivot, scaler[s])\n",
    "        for col in df_scaled:\n",
    "            display(f\"{col} -> MAX VALUE:{max(df_scaled[col])}, MIN VALUE:{min(df_scaled[col])}\")\n",
    "        df_describe = df_scaled.describe().to_excel(writer, sheet_name=f\"describe_{s}\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.boxplot(df_scaled[df_scaled.columns[1:]], vert=False, showmeans=True, meanline=True,\n",
    "                labels=df_scaled.columns[1:], patch_artist=True,\n",
    "                medianprops={'linewidth': 2, 'color': 'purple'},\n",
    "                meanprops={'linewidth': 2, 'color': 'red'})\n",
    "        plt.title(f\"boxplot_{s}\")\n",
    "        fig.savefig(f\"graph/boxplot_{s}.png\", dpi=fig.dpi)\n",
    "        fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boxplot_maxabs_scaler.png', 'boxplot_robust_scaler.png', 'corr_matrix_maxabs_scaler_kendall.png', 'corr_matrix_maxabs_scaler_pearson.png', 'corr_matrix_maxabs_scaler_spearman.png', 'corr_matrix_robust_scaler_kendall.png', 'corr_matrix_robust_scaler_pearson.png', 'corr_matrix_robust_scaler_spearman.png', 'pairplot.png']\n",
      "1 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">]\n",
      "2 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">]\n",
      "3 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">]\n",
      "4 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">]\n",
      "5 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">, <Worksheet \"graph4\">]\n",
      "6 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">, <Worksheet \"graph4\">, <Worksheet \"graph5\">]\n",
      "7 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">, <Worksheet \"graph4\">, <Worksheet \"graph5\">, <Worksheet \"graph6\">]\n",
      "8 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">, <Worksheet \"graph4\">, <Worksheet \"graph5\">, <Worksheet \"graph6\">, <Worksheet \"graph7\">]\n",
      "9 [<Worksheet \"maxabs_scaler_pearson\">, <Worksheet \"maxabs_scaler_kendall\">, <Worksheet \"maxabs_scaler_spearman\">, <Worksheet \"robust_scaler_pearson\">, <Worksheet \"robust_scaler_kendall\">, <Worksheet \"robust_scaler_spearman\">, <Worksheet \"describe_maxabs_scaler\">, <Worksheet \"describe_robust_scaler\">, <Worksheet \"graph\">, <Worksheet \"graph1\">, <Worksheet \"graph2\">, <Worksheet \"graph3\">, <Worksheet \"graph4\">, <Worksheet \"graph5\">, <Worksheet \"graph6\">, <Worksheet \"graph7\">, <Worksheet \"graph8\">]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with pd.ExcelWriter(\"output/data_corr.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\\n    df_scaled.to_excel(writer, sheet_name=\"graph\")'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = [dir for dir in os.listdir(\"graph\")]\n",
    "# print(dir_list)\n",
    "\n",
    "row = 1\n",
    "for dir in dir_list:\n",
    "    wb = openpyxl.load_workbook(\"output/data_corr.xlsx\")\n",
    "    if \"graph\" not in wb.sheetnames:\n",
    "        ws = wb.create_sheet(\"graph\")\n",
    "    else:\n",
    "        ws = wb[\"graph\"]\n",
    "    image = openpyxl.drawing.image.Image(f\"graph/{dir}\")\n",
    "    ws.add_image(image, str(f\"A{row}\"))\n",
    "    wb.save(\"output/data_corr.xlsx\")\n",
    "    row = row + 75\n",
    "\n",
    "'''with pd.ExcelWriter(\"output/data_corr.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "    df_scaled.to_excel(writer, sheet_name=\"graph\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = data_scaled[data_scaled.columns[1:]].to_numpy()\n",
    "data_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "lof_predict = clf.fit_predict(data_arr)\n",
    "results = clf.negative_outlier_factor_\n",
    "data_scaled[\"LOF\"] = results\n",
    "data_scaled[\"outlier\"] = lof_predict\n",
    "\n",
    "data_pca = PCA(n_components=2).fit_transform(data_arr)\n",
    "data_pca = pd.DataFrame(data_pca, columns=[\"pca1\", \"pca2\"])\n",
    "df_concat = data_scaled[[\"ent\", \"LOF\", \"outlier\"]]\n",
    "data_pca = pd.concat([df_concat, data_pca], axis=1)\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "seed(1)\n",
    "# thr = -12\n",
    "# plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "# plt.figure(figsize=(1,1))\n",
    "plt.scatter(data_pca[\"pca1\"].loc[(data_pca[\"outlier\"]==1)], data_pca[\"pca2\"].loc[(data_pca[\"outlier\"]==1)])\n",
    "for i in data_pca[\"pca1\"].loc[(data_pca[\"outlier\"]==-1)]:\n",
    "    c = 0 # random() * 20\n",
    "    plt.scatter(i, data_pca[\"pca2\"].loc[data_pca[\"pca1\"]==i], edgecolors=\"black\", color=\"red\") # data_pca[\"pca1\"].loc[(data_pca[\"LOF\"]<=thr)], data_pca[\"pca2\"].loc[(data_pca[\"LOF\"]<=thr)], edgecolors=\"black\", color=\"red\")\n",
    "    plt.text(i+c, data_pca[\"pca2\"].loc[data_pca[\"pca1\"]==i]+c, \n",
    "            ([e for e in data_pca[\"ent\"].loc[data_pca[\"pca1\"]==i]][0], round(float([d for d in data_pca[\"LOF\"].loc[data_pca[\"pca1\"]==i]][0]), 1)), ha=\"center\")\n",
    "    # print(c)\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df_lof = data_scaled[data_scaled[\"outlier\"]==1]\n",
    "display(data_scaled.sort_values(by=\"LOF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — — — — — — -Setting Up Color Codes — — — — — — — — — — — -\n",
    "# colors_plot = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(labels))]\n",
    "\n",
    "df_pca3_lof = PCA(n_components=3).fit_transform(data_arr)\n",
    "df_pca3_lof = pd.DataFrame(df_pca3_lof, columns=[\"pca1\", \"pca2\", \"pca3\"])\n",
    "df_concat = data_scaled[[\"ent\", \"LOF\", \"outlier\"]]\n",
    "df_pca3_lof = pd.concat([df_concat, df_pca3_lof], axis=1)\n",
    "\n",
    "# thr = -12\n",
    "\n",
    "fig = plt.figure(figsize = (20, 14))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "for k in range(len(df_pca3_lof)):\n",
    "    \n",
    "    ent = df_pca3_lof[\"ent\"].loc[k]\n",
    "    lof = df_pca3_lof[\"LOF\"].loc[k]\n",
    "    outlier = df_pca3_lof[\"outlier\"].loc[k]\n",
    "    pca1 = df_pca3_lof[\"pca1\"].loc[k]\n",
    "    pca2 = df_pca3_lof[\"pca2\"].loc[k]\n",
    "    pca3 = df_pca3_lof[\"pca3\"].loc[k]\n",
    "\n",
    "\n",
    "    # kmeans_cc1 = df_clust[\"kmeans_cc1\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    # kmeans_cc2 = df_clust[\"kmeans_cc2\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    # kmeans_cc3 = df_clust[\"kmeans_cc3\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "\n",
    "    if outlier == -1:\n",
    "    \n",
    "        ax.plot(\n",
    "                    pca1,\n",
    "                    pca2,\n",
    "                    pca3,\n",
    "                    \"o\",\n",
    "                    markerfacecolor=\"red\",\n",
    "                    markeredgecolor=\"black\",\n",
    "                    markersize=10,\n",
    "                )\n",
    "\n",
    "        c = random() * 2\n",
    "        ax.text(pca1+c, pca2+c, pca3+c, (ent, round(float(lof), 1)), ha=\"center\")\n",
    "\n",
    "        '''# — — — — — — -Annotate Centroids — — — — — — — — — — — -\n",
    "        ax.plot(\n",
    "                    kmeans_cc1,\n",
    "                    kmeans_cc2,\n",
    "                    kmeans_cc3,\n",
    "                    \"o\",\n",
    "                    markerfacecolor=color,\n",
    "                    markeredgecolor=\"k\",\n",
    "                    markersize=10,\n",
    "                )'''\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.plot(\n",
    "                    pca1,\n",
    "                    pca2,\n",
    "                    pca3,\n",
    "                    \"o\",\n",
    "                    markerfacecolor=\"blue\",\n",
    "                    markeredgecolor=\"white\",\n",
    "                    markersize=5,\n",
    "                )\n",
    "# — — — — — — -Add title to the plot — — — — — — — — — — — -\n",
    "# plt.title(\"KMeans with PCA - OUTLIERS not graphed\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "df_pca3_lof = df_pca3_lof[df_pca3_lof[\"outlier\"]==1].drop([\"LOF\", \"outlier\"], axis=1)\n",
    "# df_pca3_lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "# Import the digits’ dataset available in sklearn.datasets package\n",
    "# from sklearn.datasets import load_digits\n",
    "'''“””\n",
    "Instead of using all 64 attributes of the dataset, we use Principal Component Analysis (PCA) \n",
    "to reduce the dimensions of features set such that most of the useful information is covered.\n",
    "“””'''\n",
    "from sklearn.decomposition import PCA\n",
    "''' “””\n",
    "Import module for standardizing the dataset i.e. rescaling the data such that its has mean of 0 and standard deviation of 1\n",
    "“””'''\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#Scale the data\n",
    "#data_scaled = data_arr\n",
    "#robust_scaler = RobustScaler().fit(data_arr)\n",
    "#robust_scaler.transform(data_scaled)\n",
    "'''“””\n",
    "Compute number of output classes i.e. number of digits for which we have the data (here 10 (0-9))\n",
    "“””'''\n",
    "num_digits = 5 # len(np.unique(dataset.target)) \n",
    "data_pca = PCA(n_components=3).fit_transform(data_arr)\n",
    "'''“””\n",
    "PCA constructs new components by linear combinations of original features. \n",
    "‘n_components’ parameter denotes the number of newly formed components to be considered. \n",
    "fit_transform() method fits the PCA models and performs dimensionality reduction on digit_data.\n",
    "“””'''\n",
    "h = 0.02 #step size of the mesh \n",
    "#Minimum and maximum x-coordinates\n",
    "xmin, xmax = data_pca[:, 0].min() - 1, data_pca[:, 0].max() + 1\n",
    "#Minimum and maximum y-coordinates\n",
    "ymin, ymax = data_pca[:, 1].min() - 1, data_pca[:, 1].max() + 1\n",
    "#Minimum and maximum z-coordinates\n",
    "zmin, zmax = data_pca[:, 2].min() - 1, data_pca[:, 2].max() + 1\n",
    "xx, yy, zz = np.meshgrid(np.arange(xmin, xmax, h), np.arange(ymin, ymax, h), np.arange(zmin, zmax, h))\n",
    "models = [\n",
    "     (\n",
    "         KMedoids(metric=\"manhattan\", n_clusters=num_digits, \n",
    "         init=\"heuristic\", max_iter=1000),\"Manhattan metric\",\n",
    "     ),\n",
    "     (\n",
    "         KMedoids(metric=\"euclidean\", n_clusters=num_digits,  \n",
    "         init=\"heuristic\", max_iter=1000),\"Euclidean metric\",\n",
    "     ),\n",
    "     (KMedoids(metric=\"cosine\", n_clusters=num_digits, init=\"heuristic\", \n",
    "      max_iter=1000), \"Cosine metric\", ),\n",
    "]\n",
    "#number of rows = integer(ceiling(number of model variants/2))\n",
    "num_rows = int(np.ceil(len(models) / 2.0))\n",
    "#number of columns\n",
    "num_cols = 3\n",
    "#Clear the current figure first (if any)\n",
    "plt.clf()\n",
    "#Initialize dimensions of the plot\n",
    "plt.figure(figsize=(15,10))\n",
    "'''“””\n",
    "The ‘models’ array defined in step (6) contains three tuples, each having a model variant’s parameters and its descriptive text. \n",
    "We iterate through each of the tuples, fit the data to the model and plot the results.\n",
    "“””'''\n",
    "for i, (model, description) in enumerate(models):\n",
    "    # Fit each point in the mesh to the model\n",
    "    model.fit(data_pca)\n",
    "#Predict the labels for points in the mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel(), zz.ravel()])\n",
    "    # Put the result  into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "#Subplot for the ith model variant\n",
    "    plt.subplot(num_cols, num_rows, i + 1)\n",
    "#Display the subplot\n",
    "    plt.imshow(\n",
    "        Z,    #data to be plotted\n",
    "        interpolation=\"nearest\",\n",
    "#bounding box coordinates (left,right,bottom,top)\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        cmap=plt.cm.Paired,  #colormap\n",
    "        aspect=\"auto\", #aspect ratio of the axes\n",
    "        origin=\"lower\",  #set origin as lower left corner of the axes\n",
    "    )\n",
    "    plt.plot(\n",
    "        data_pca[:, 0], data_pca[:, 1], data_pca[:, 2], \"k.\", markersize=2, alpha=0.3\n",
    "    )\n",
    "    # Plot the centroids as white cross marks\n",
    "    centroids = model.cluster_centers_\n",
    "    plt.scatter(\n",
    "        centroids[:, 0],\n",
    "        centroids[:, 1],\n",
    "        centroids[:, 2],\n",
    "        marker=\"x\",\n",
    "        s=169,  #marker’s size (points^2)\n",
    "        linewidths=3, #width of boundary lines\n",
    "        color=\"w\",  #white color for centroids markings\n",
    "        zorder=10,  #drawing order of axes\n",
    "    )\n",
    "    #describing text of the tuple will be title of the subplot\n",
    "    plt.title(description)  \n",
    "    plt.xlim(xmin, xmax)  #limits of x-coordinates\n",
    "    plt.ylim(ymin, ymax)  #limits of y-coordinates\n",
    "    plt.ylim(zmin, zmax)  #limits of y-coordinates\n",
    "    plt.xticks(())   \n",
    "    plt.yticks(())\n",
    "    plt.zticks(())\n",
    "#Upper title of the whole plot\n",
    "plt.suptitle(\n",
    "#Text to be displayed\n",
    "    \"K-Medoids algorithm implemented with different metrics\\n\\n\",\n",
    "    fontsize=20,  #size of the fonts\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# data_pca = PCA(n_components=3).fit_transform(data_arr)\n",
    "\n",
    "# df_pca3_lof\n",
    "\n",
    "k_med = KMedoids(metric=\"cosine\", n_clusters=5, \n",
    "         init=\"heuristic\", max_iter=10000, method=\"pam\").fit(df_pca3_lof[df_pca3_lof.columns[1:]])\n",
    "\n",
    "k_means = KMeans(n_clusters=5, n_init=100, max_iter=10000, algorithm=\"elkan\").fit(df_pca3_lof[df_pca3_lof.columns[1:]])\n",
    "\n",
    "y_k_med = k_med.fit_predict(df_pca3_lof[df_pca3_lof.columns[1:]])\n",
    "\n",
    "y_k_means = k_means.fit_predict(df_pca3_lof[df_pca3_lof.columns[1:]])\n",
    "\n",
    "kmed_labels = k_med.labels_\n",
    "labels = set(kmed_labels)\n",
    "\n",
    "kmeans_labels = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_med_clust = k_med.cluster_centers_ # PCA(n_components=2).fit_transform(robust_scaler.fit_transform(k_med.cluster_centers_))\n",
    "k_means_clust = k_means.cluster_centers_ # PCA(n_components=2).fit_transform(robust_scaler.fit_transform(k_means.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust = pd.DataFrame(df_pca3_lof, columns=[\"pca1\", \"pca2\", \"pca3\"])\n",
    "df_clust[\"ent\"] = df_pca3_lof[\"ent\"]\n",
    "df_clust[\"kmed\"] = y_k_med\n",
    "df_clust[\"kmeans\"] = y_k_means\n",
    "df_clust[\"kmed_cc1\"] = [k_med_clust[c, 0] for c in df_clust[\"kmed\"]]\n",
    "df_clust[\"kmed_cc2\"] = [k_med_clust[c, 1] for c in df_clust[\"kmed\"]]\n",
    "df_clust[\"kmed_cc3\"] = [k_med_clust[c, 2] for c in df_clust[\"kmed\"]]\n",
    "df_clust[\"kmeans_cc1\"] = [k_means_clust[c, 0] for c in df_clust[\"kmeans\"]]\n",
    "df_clust[\"kmeans_cc2\"] = [k_means_clust[c, 1] for c in df_clust[\"kmeans\"]]\n",
    "df_clust[\"kmeans_cc3\"] = [k_means_clust[c, 2] for c in df_clust[\"kmeans\"]]\n",
    "# df_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explained_variance = data_pca.explained_variance_ratio_\n",
    "df_explained_variance = np.insert(df_explained_variance, 0, 0)\n",
    "cumulative_variance = np.cumsum(np.round(df_explained_variance, decimals=3))\n",
    "pca_variance = pd.DataFrame(['', 'pc1', 'pc2', 'pc3'], columns=['pc'])\n",
    "df_explained_variance = pd.DataFrame(df_explained_variance, columns=['explained_variance'])\n",
    "cumulative_variance = pd.DataFrame(cumulative_variance, columns=['cumulative_variance'])\n",
    "df_explained_variance = pd.concat([pca_variance, df_explained_variance, cumulative_variance], axis=1)\n",
    "print(df_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmed_labels = df_clust[\"kmed\"].unique() # df_clust[\"ent\"][df_clust[\"kmed\"]==0]\n",
    "\n",
    "'''for label in kmed_labels:\n",
    "    display(df_clust[df_clust[\"kmed\"]==label])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_clust[\"pca1\"], df_clust[\"pca2\"])\n",
    "plt.scatter(df_clust[\"kmed_cc1\"], df_clust[\"kmed_cc2\"], edgecolors=\"black\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_clust[\"pca1\"], df_clust[\"pca2\"])\n",
    "plt.scatter(df_clust[\"kmeans_cc1\"], df_clust[\"kmeans_cc2\"], edgecolors=\"black\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — — — — — — -Setting Up Color Codes — — — — — — — — — — — -\n",
    "colors_plot = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(labels))]\n",
    "\n",
    "fig = plt.figure(figsize = (20, 14))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "for k, col in zip(labels, colors_plot):\n",
    "    class_member_mask = df_clust[\"kmed\"] == k\n",
    " \n",
    "    # — — — — — — -Setting datapoint Feature X and Feature Y — — — — — — — — — — — -\n",
    "    pca1 = df_clust[\"pca1\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    pca2 = df_clust[\"pca2\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    pca3 = df_clust[\"pca3\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "\n",
    "\n",
    "    kmed_cc1 = df_clust[\"kmed_cc1\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    kmed_cc2 = df_clust[\"kmed_cc2\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    kmed_cc3 = df_clust[\"kmed_cc3\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "\n",
    "    color = tuple(col)\n",
    " \n",
    "    # — — — — — — -Plotting Feature X and Feature Y for each cluster labels — — — — — — — — — — — -\n",
    "    ax.plot(\n",
    "                pca1,\n",
    "                pca2,\n",
    "                pca3,\n",
    "                \"o\",\n",
    "                markerfacecolor=color,\n",
    "                markeredgecolor=\"white\",\n",
    "                markersize=10,\n",
    "            )\n",
    "\n",
    "    # — — — — — — -Annotate Centroids — — — — — — — — — — — -\n",
    "    ax.plot(\n",
    "                kmed_cc1,\n",
    "                kmed_cc2,\n",
    "                kmed_cc3,\n",
    "                \"o\",\n",
    "                markerfacecolor=color,\n",
    "                markeredgecolor=\"k\",\n",
    "                markersize=10,\n",
    "            )\n",
    "# — — — — — — -Add title to the plot — — — — — — — — — — — -\n",
    "plt.title(\"KMedoids with PCA - OUTLIERS not graphed\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — — — — — — -Setting Up Color Codes — — — — — — — — — — — -\n",
    "colors_plot = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(labels))]\n",
    "\n",
    "fig = plt.figure(figsize = (20, 14))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "for k, col in zip(labels, colors_plot):\n",
    "    class_member_mask = df_clust[\"kmeans\"] == k\n",
    " \n",
    "    # — — — — — — -Setting datapoint Feature X and Feature Y — — — — — — — — — — — -\n",
    "    pca1 = df_clust[\"pca1\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    pca2 = df_clust[\"pca2\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    pca3 = df_clust[\"pca3\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "\n",
    "\n",
    "    kmeans_cc1 = df_clust[\"kmeans_cc1\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    kmeans_cc2 = df_clust[\"kmeans_cc2\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "    kmeans_cc3 = df_clust[\"kmeans_cc3\"][class_member_mask]#.loc[(df_clust[\"pca1\"]<=10)&(df_clust[\"pca2\"]<=10)]\n",
    "\n",
    "    color = tuple(col)\n",
    " \n",
    "    # — — — — — — -Plotting Feature X and Feature Y for each cluster labels — — — — — — — — — — — -\n",
    "    ax.plot(\n",
    "                pca1,\n",
    "                pca2,\n",
    "                pca3,\n",
    "                \"o\",\n",
    "                markerfacecolor=color,\n",
    "                markeredgecolor=\"white\",\n",
    "                markersize=10,\n",
    "            )\n",
    "\n",
    "    # — — — — — — -Annotate Centroids — — — — — — — — — — — -\n",
    "    ax.plot(\n",
    "                kmeans_cc1,\n",
    "                kmeans_cc2,\n",
    "                kmeans_cc3,\n",
    "                \"o\",\n",
    "                markerfacecolor=color,\n",
    "                markeredgecolor=\"k\",\n",
    "                markersize=10,\n",
    "            )\n",
    "# — — — — — — -Add title to the plot — — — — — — — — — — — -\n",
    "plt.title(\"KMeans with PCA - OUTLIERS not graphed\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_k_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_med.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "silhouette_avg = silhouette_score(data_arr, y_k_med)\n",
    "print(silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_silhouette_values = silhouette_samples(data_pca, y_k_med)\n",
    "for i in range(3):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[y_k_med == i]\n",
    "    print(np.mean(ith_cluster_silhouette_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('cbbm-RQGQLPr7-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bd4a477d0876910250915e3e9f7d6b6cb97ff716c94d5f9b489478001bf4dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
